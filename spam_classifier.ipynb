{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import email\n",
    "import email.policy\n",
    "import re\n",
    "from html import unescape\n",
    "import nltk\n",
    "import urlextract\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try visualization https://towardsdatascience.com/spam-classifier-in-python-from-scratch-27a98ddd8e73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the data\n",
    "\n",
    "  - spam: 500 spam messages, all received from non-spam-trap sources.\n",
    "\n",
    "  - easy_ham: 2500 non-spam messages.  These are typically quite easy to\n",
    "    differentiate from spam, since they frequently do not contain any spammish\n",
    "    signatures (like HTML etc).\n",
    "  \n",
    "Source: https://spamassassin.apache.org/old/publiccorpus/readme.html\n",
    "\n",
    "\n",
    "\n",
    "files = [\"20021010_easy_ham.tar.bz2\",\n",
    "         \"20021010_hard_ham.tar.bz2\",\n",
    "         \"20021010_spam.tar.bz2\",\n",
    "         \"20030228_easy_ham.tar.bz2\",\n",
    "         \"20030228_easy_ham_2.tar.bz2\",\n",
    "         \"20030228_hard_ham.tar.bz2\",\n",
    "         \"20030228_spam.tar.bz2\",\n",
    "         \"20030228_spam_2.tar.bz2\",\n",
    "         \"20050311_spam_2.tar.bz2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "DATASETS_PATH = os.path.join(\"Datasets\")\n",
    "FILES = [\"20030228_easy_ham.tar.bz2\",\n",
    "         \"20030228_spam.tar.bz2\",]\n",
    "DOWNLOAD_URLS = [DOWNLOAD_ROOT + name for name in FILES]\n",
    "\n",
    "def fetch_data():\n",
    "    if not os.path.isdir(DATASETS_PATH):\n",
    "        os.makedirs(DATASETS_PATH)\n",
    "        \n",
    "    for filename, url in list(zip(FILES, DOWNLOAD_URLS)):\n",
    "        path = os.path.join(DATASETS_PATH, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        current_tar_file = tarfile.open(path)\n",
    "        current_tar_file.extractall(path=DATASETS_PATH)\n",
    "        current_tar_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam emails: 500 \n",
      "Non-spam emails: 2500\n"
     ]
    }
   ],
   "source": [
    "spam_path = os.path.join(DATASETS_PATH, 'spam')\n",
    "ham_path = os.path.join(DATASETS_PATH, 'easy_ham')\n",
    "spam_filenames = [filename for filename in os.listdir(spam_path) if len(filename) > 10]\n",
    "ham_filenames = [filename for filename in os.listdir(ham_path) if len(filename) > 10]\n",
    "\n",
    "print(\"Spam emails:\", len(spam_filenames), \"\\nNon-spam emails:\", len(ham_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_email(is_spam, filename):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(DATASETS_PATH, directory, filename), \"rb\") as f:        \n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "\n",
    "    \n",
    "spam_emails = [read_email(is_spam=True, filename=filename) for filename in spam_filenames]\n",
    "ham_emails = [read_email(False, filename) for filename in ham_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n",
      "<HTML><HEAD>\n",
      "<META content=\"text/html; charset=windows-1252\" http-equiv=Content-Type>\n",
      "<META content=\"MSHTML 5.00.2314.1000\" name=GENERATOR></HEAD>\n",
      "<BODY><!-- Inserted by Calypso -->\n",
      "<TABLE border=0 cellPadding=0 cellSpacing=2 id=_CalyPrintHeader_ rules=none \n",
      "style=\"COLOR: black; DISPLAY: none\" width=\"100%\">\n",
      "  <TBODY>\n",
      "  <TR>\n",
      "    <TD colSpan=3>\n",
      "      <HR color=black noShade SIZE=1>\n",
      "    </TD></TR></TD></TR>\n",
      "  <TR>\n",
      "    <TD colSpan=3>\n",
      "      <HR color=black noShade SIZE=1>\n",
      "    </TD></TR></TBODY></TABLE><!-- End Calypso --><!-- Inserted by Calypso --><FONT \n",
      "color=#000000 face=VERDANA,ARIAL,HELVETICA size=-2><BR></FONT></TD></TR></TABLE><!-- End Calypso --><FONT color=#ff0000 \n",
      "face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
      "<CENTER>Save up to 70% on Life Insurance.</CENTER></FONT><FONT color=#ff0000 \n",
      "face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
      "<CENTER>Why Spend More Than You Have To?\n",
      "<CENTER><FONT color=#ff0000 face=\"Copperplate Gothic Bold\" size=5 PTSIZE=\"10\">\n",
      "<CENTER>Life Quote Savings\n",
      "<CENTER>\n",
      "<P align=left></P>\n",
      "<P align=left></P></FONT></U></I></B><BR></FONT></U></B></U></I>\n",
      "<P></P>\n",
      "<CENTER>\n",
      "<TABLE border=0 borderColor=#111111 cellPadding=0 cellSpacing=0 width=650>\n",
      "  <TBODY></TBODY></TABLE>\n",
      "<TABLE border=0 borderColor=#111111 cellPadding=5 cellSpacing=0 width=650>\n",
      "  <TBODY>\n",
      "  <TR>\n",
      "    <TD colSpan=2 width=\"35%\"><B><FONT face=Verdana size=4>Ensuring your \n",
      "      family's financial security is very important. Life Quote Savings makes \n",
      "      buying life insurance simple and affordable. We Provide FREE Access to The \n",
      "      Very Best Companies and The Lowest Rates.</FONT></B></TD></TR>\n",
      "  <TR>\n",
      "    <TD align=middle vAlign=top width=\"18%\">\n",
      "      <TABLE borderColor=#111111 width=\"100%\">\n",
      "        <TBODY>\n",
      "        <TR>\n",
      "          <TD style=\"PADDING-LEFT: 5px; PADDING-RIGHT: 5px\" width=\"100%\"><FONT \n",
      "            face=Verdana size=4><B>Life Quote Savings</B> is FAST, EASY and \n",
      "            SAVES you money! Let us help you get started with the best values in \n",
      "            the country on new coverage. You can SAVE hundreds or even thousands \n",
      "            of dollars by requesting a FREE quote from Lifequote Savings. Our \n",
      "            service will take you less than 5 minutes to complete. Shop and \n",
      "            compare. SAVE up to 70% on all types of Life insurance! \n",
      "</FONT></TD></TR>\n",
      "        <TR><BR><BR>\n",
      "          <TD height=50 style=\"PADDING-LEFT: 5px; PADDING-RIGHT: 5px\" \n",
      "          width=\"100%\">\n",
      "            <P align=center><B><FONT face=Verdana size=5><A \n",
      "            href=\"http://website.e365.cc/savequote/\">Click Here For Your \n",
      "            Free Quote!</A></FONT></B></P></TD>\n",
      "          <P><FONT face=Verdana size=4><STRONG>\n",
      "          <CENTER>Protecting your family is the best investment you'll ever \n",
      "          make!<BR></B></TD></TR>\n",
      "        <TR><BR><BR></STRONG></FONT></TD></TR></TD></TR>\n",
      "        <TR></TR></TBODY></TABLE>\n",
      "      <P align=left><FONT face=\"Arial, Helvetica, sans-serif\" size=2></FONT></P>\n",
      "      <P></P>\n",
      "      <CENTER><BR><BR><BR>\n",
      "      <P></P>\n",
      "      <P align=left><BR></B><BR><BR><BR><BR></P>\n",
      "      <P align=center><BR></P>\n",
      "      <P align=left><BR></B><BR><BR></FONT>If you are in receipt of this email \n",
      "      in error and/or wish to be removed from our list, <A \n",
      "      href=\"mailto:coins@btamail.net.cn\">PLEASE CLICK HERE</A> AND TYPE REMOVE. If you \n",
      "      reside in any state which prohibits e-mail solicitations for insurance, \n",
      "      please disregard this \n",
      "      email.<BR></FONT><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR></FONT></P></CENTER></CENTER></TR></TBODY></TABLE></CENTER></CENTER></CENTER></CENTER></CENTER></BODY></HTML>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spam examle\n",
    "print(spam_emails[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Scotsman - 22 August 2002\n",
      "\n",
      " Playboy wants to go out with a bang \n",
      " \n",
      " \n",
      " AN AGEING Berlin playboy has come up with an unusual offer to lure women into\n",
      " his bed - by promising the last woman he sleeps with an inheritance of 250,000\n",
      " (Â£160,000). \n",
      " \n",
      " Rolf Eden, 72, a Berlin disco owner famous for his countless sex partners,\n",
      " said he could imagine no better way to die than in the arms of an attractive\n",
      " young woman - preferably under 30. \n",
      " \n",
      " \"I put it all in my last will and testament - the last woman who sleeps with\n",
      " me gets all the money,\" Mr Eden told Bild newspaper. \n",
      " \n",
      " \"I want to pass away in the most beautiful moment of my life. First a lot of\n",
      " fun with a beautiful woman, then wild sex, a final orgasm - and it will all\n",
      " end with a heart attack and then IÂm gone.\" \n",
      " \n",
      " Mr Eden, who is selling his nightclub this year, said applications should be\n",
      " sent in quickly because of his age. \"It could end very soon,\" he said.\n",
      "\n",
      "\n",
      "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
      "4 DVDs Free +s&p Join Now\n",
      "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
      "---------------------------------------------------------------------~->\n",
      "\n",
      "To unsubscribe from this group, send an email to:\n",
      "forteana-unsubscribe@egroups.com\n",
      "\n",
      " \n",
      "\n",
      "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nonspam example\n",
    "print(ham_emails[6].get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ham_emails + spam_emails\n",
    "y = [0]*len(ham_emails) + [1]*len(spam_emails)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting emails into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(raw_html):\n",
    "    cleantext = re.sub(r'<a.+?>', ' href url ', raw_html, flags=re.I | re.S | re.M)\n",
    "    cleantext = re.sub(r'<.+?>', ' ', cleantext, flags=re.S | re.M)\n",
    "    cleantext = re.sub(r'\\s+', ' ', cleantext) \n",
    "    #cleantext = re.sub(r'(\\s*\\n)+', '\\n', cleantext, flags=re.M | re.S)\n",
    "    return unescape(cleantext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Save up to 70% on Life Insurance. Why Spend More Than You Have To? Life Quote Savings Ensuring your family's financial security is very important. Life Quote Savings makes buying life insurance simple and affordable. We Provide FREE Access to The Very Best Companies and The Lowest Rates. Life Quote Savings is FAST, EASY and SAVES you money! Let us help you get started with the best values in the country on new coverage. You can SAVE hundreds or even thousands of dollars by requesting a FREE quote from Lifequote Savings. Our service will take you less than 5 minutes to complete. Shop and compare. SAVE up to 70% on all types of Life insurance! href url Click Here For Your Free Quote! Protecting your family is the best investment you'll ever make! If you are in receipt of this email in error and/or wish to be removed from our list, href url PLEASE CLICK HERE AND TYPE REMOVE. If you reside in any state which prohibits e-mail solicitations for insurance, please disregard this email. \n"
     ]
    }
   ],
   "source": [
    "cleaned_sample = clean_html(spam_emails[0].get_content())\n",
    "print(cleaned_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(raw_email):\n",
    "    html = None\n",
    "    for part in raw_email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if ctype not in ('text/html', 'text/plain'):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except:\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return clean_html(html)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Save up to 70% on Life Insurance. Why Spend More Than You Have To? Life Quote Savings Ensuring your ...\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(spam_emails[0])[:100], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting words in email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universe => univers\n",
      "Universal => univers\n",
      "University => univers\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "for word in (\"Universe\", \"Universal\", \"University\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "    print(word, \"=>\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universe, Universal, and University have the same stem but different meanings, however that wont be a huge problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www.adclick.ws/p.cfm?o=315&s=pk007', 'http://www.adclick.ws/p.cfm?o=249&s=pk007', 'http://www.adclick.ws/p.cfm?o=245&s=pk002', 'http://www.adclick.ws/p.cfm?o=259&s=pk007', 'http://www.adclick.ws/p.cfm?o=283&s=pk007', 'http://www.qves.com/trim/?ilug@linux.ie%7C17%7C114258', 'http://www.linux.ie/mailman/listinfo/ilug']\n"
     ]
    }
   ],
   "source": [
    "url_extractor = urlextract.URLExtract()\n",
    "print(url_extractor.find_urls(email_to_text(spam_emails[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):    \n",
    "    def __init__(self, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "        self.replace_urls = replace_urls\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        if not isinstance(X, list):\n",
    "            X = [X]\n",
    "        for email in X:            \n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls:\n",
    "                urls = url_extractor.find_urls(text)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', ' NUMBER ', text, flags=re.M | re.S)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M | re.S)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'save': 8, 'you': 8, 'to': 6, 'life': 6, 'and': 6, 'quot': 5, 'the': 5, 'insur': 4, 'in': 4, 'number': 3, 'on': 3, 'your': 3, 'is': 3, 'free': 3, 'best': 3, 'of': 3, 'up': 2, 'than': 2, 'famili': 2, 'veri': 2, 'make': 2, 'or': 2, 'from': 2, 'our': 2, 'type': 2, 'href': 2, 'url': 2, 'click': 2, 'here': 2, 'for': 2, 'if': 2, 'thi': 2, 'email': 2, 'remov': 2, 'pleas': 2, 'whi': 1, 'spend': 1, 'more': 1, 'have': 1, 'ensur': 1, 's': 1, 'financi': 1, 'secur': 1, 'import': 1, 'buy': 1, 'simpl': 1, 'afford': 1, 'we': 1, 'provid': 1, 'access': 1, 'compani': 1, 'lowest': 1, 'rate': 1, 'fast': 1, 'easi': 1, 'money': 1, 'let': 1, 'us': 1, 'help': 1, 'get': 1, 'start': 1, 'with': 1, 'valu': 1, 'countri': 1, 'new': 1, 'coverag': 1, 'can': 1, 'hundr': 1, 'even': 1, 'thousand': 1, 'dollar': 1, 'by': 1, 'request': 1, 'a': 1, 'lifequot': 1, 'servic': 1, 'will': 1, 'take': 1, 'less': 1, 'minut': 1, 'complet': 1, 'shop': 1, 'compar': 1, 'all': 1, 'protect': 1, 'invest': 1, 'll': 1, 'ever': 1, 'are': 1, 'receipt': 1, 'error': 1, 'wish': 1, 'be': 1, 'list': 1, 'resid': 1, 'ani': 1, 'state': 1, 'which': 1, 'prohibit': 1, 'e': 1, 'mail': 1, 'solicit': 1, 'disregard': 1}),\n",
       "       Counter({'number': 8, 'url': 7, 'the': 4, 'linux': 3, 'to': 2, 'day': 2, 'you': 2, 'list': 2, 'ie': 2, 'fight': 1, 'risk': 1, 'of': 1, 'cancer': 1, 'slim': 1, 'down': 1, 'guarante': 1, 'lose': 1, 'lb': 1, 'in': 1, 'get': 1, 'child': 1, 'support': 1, 'deserv': 1, 'free': 1, 'legal': 1, 'advic': 1, 'join': 1, 'web': 1, 's': 1, 'fastest': 1, 'grow': 1, 'singl': 1, 'commun': 1, 'start': 1, 'your': 1, 'privat': 1, 'photo': 1, 'album': 1, 'onlin': 1, 'have': 1, 'a': 1, 'wonder': 1, 'offer': 1, 'manag': 1, 'prizemama': 1, 'if': 1, 'wish': 1, 'leav': 1, 'thi': 1, 'pleas': 1, 'use': 1, 'link': 1, 'below': 1, 'irish': 1, 'user': 1, 'group': 1, 'ilug': 1, 'for': 1, 'un': 1, 'subscript': 1, 'inform': 1, 'maintain': 1, 'listmast': 1}),\n",
       "       Counter({'number': 8, 'url': 6, 'the': 4, 'to': 2, 'day': 2, 'you': 2, 'fight': 1, 'risk': 1, 'of': 1, 'cancer': 1, 'slim': 1, 'down': 1, 'guarante': 1, 'lose': 1, 'lb': 1, 'in': 1, 'get': 1, 'child': 1, 'support': 1, 'deserv': 1, 'free': 1, 'legal': 1, 'advic': 1, 'join': 1, 'web': 1, 's': 1, 'fastest': 1, 'grow': 1, 'singl': 1, 'commun': 1, 'start': 1, 'your': 1, 'privat': 1, 'photo': 1, 'album': 1, 'onlin': 1, 'have': 1, 'a': 1, 'wonder': 1, 'offer': 1, 'manag': 1, 'prizemama': 1, 'if': 1, 'wish': 1, 'leav': 1, 'thi': 1, 'list': 1, 'pleas': 1, 'use': 1, 'link': 1, 'below': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_email = spam_emails[:3]\n",
    "some_email_wordcounts = EmailToWordCounterTransformer().fit_transform(some_email)\n",
    "some_email_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "Now it's time to vectorize all counted words:\n",
    " \n",
    "1. First I will count all words\n",
    "2. Most common of them I will store in a N=1000 size dictionary \n",
    "3. All my vectors I will store in a <a href=\"https://machinelearningmastery.com/sparse-matrices-for-machine-learning/\">sparce matrix</a> to decrease computational and space costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):    \n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()  \n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count,10)  # to prevent some word occurrence more than 10 times at one email\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}  # +1 for top-1 (not top-0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for i, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(i)                \n",
    "                cols.append(self.vocabulary_.get(word, 0))  # Store a word's index. \n",
    "                                                            # If a word isn't common then append it to index 0\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "few_vectors = vocab_transformer.fit_transform(some_email_wordcounts)\n",
    "few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number': 1,\n",
       " 'url': 2,\n",
       " 'the': 3,\n",
       " 'you': 4,\n",
       " 'to': 5,\n",
       " 'save': 6,\n",
       " 'life': 7,\n",
       " 'and': 8,\n",
       " 'in': 9,\n",
       " 'quot': 10}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top N=10 of most common words\n",
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,   3,   2,   5,   8,   6,   8,   6,   6,   4,   5],\n",
       "       [ 62,   8,   7,   4,   2,   2,   0,   0,   0,   1,   0],\n",
       "       [ 46,   8,   6,   4,   2,   2,   0,   0,   0,   1,   0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array shows that the first email has 126 non common words, 3 'number', 2 'url', ... , 4 'in', 5 'quot'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = Pipeline([\n",
    "    ('email_to_words', EmailToWordCounterTransformer()),\n",
    "    ('words_to_vectors', WordCounterToVectorTransformer()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clsf = LogisticRegression(solver='liblinear', random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.980, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.988, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.985, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(log_clsf, X_train_prepared, y_train, cv=3, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.42%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:0.2f}%\".format(100*score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 96.40%\n",
      "Recall: 95.54%\n"
     ]
    }
   ],
   "source": [
    "log_clsf = LogisticRegression(solver='liblinear', random_state=11)\n",
    "log_clsf.fit(X_train_prepared, y_train)\n",
    "\n",
    "X_test_prepared = preprocess_pipeline.transform(X_test)\n",
    "y_test_predicted = log_clsf.predict(X_test_prepared)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100*precision_score(y_test, y_test_predicted)))\n",
    "print(\"Recall: {:.2f}%\".format(100*recall_score(y_test, y_test_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_letter = preprocess_pipeline.transform(spam_emails[400])\n",
    "hui = log_clsf.predict(spam_letter)\n",
    "hui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = log_clsf.coef_[0]\n",
    "vocabulary = preprocess_pipeline.named_steps['words_to_vectors'].vocabulary_\n",
    "vocabulary['noncommon'] = 0\n",
    "words_and_coefs = list(zip(coefs, vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anti spam markers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-2.2243118301081775, 'wrote'),\n",
       " (-1.0232320816484044, 'been'),\n",
       " (-0.973389203892379, 'have'),\n",
       " (-0.7863059640851457, 'look'),\n",
       " (-0.5554670050317184, 'net'),\n",
       " (-0.5392427043143603, 'do'),\n",
       " (-0.5272890265411504, 'can'),\n",
       " (-0.5260879941338577, 'sourc'),\n",
       " (-0.5163429078308354, 'becaus'),\n",
       " (-0.5066237762248326, 'be'),\n",
       " (-0.5051787429633611, 'is'),\n",
       " (-0.4982470746974006, 'ie'),\n",
       " (-0.4979172605048754, 'our'),\n",
       " (-0.485056644814553, 's'),\n",
       " (-0.47993575056843324, 'take'),\n",
       " (-0.47069445681888683, 'are'),\n",
       " (-0.4704395297859096, 'email'),\n",
       " (-0.4518127945719671, 'and'),\n",
       " (-0.43729147474824137, 'use'),\n",
       " (-0.40166494648811085, 'group'),\n",
       " (-0.39795745231991847, 'some'),\n",
       " (-0.39671030045785055, 'industri'),\n",
       " (-0.39192369412847267, '_______________________________________________'),\n",
       " (-0.38991912095000647, 'also'),\n",
       " (-0.3763136331092111, 'like'),\n",
       " (-0.3536347323509027, 'too'),\n",
       " (-0.3522206698741136, 'link'),\n",
       " (-0.3506148255129047, 'within'),\n",
       " (-0.3444201866993814, 'right'),\n",
       " (-0.3431566674827539, 'through'),\n",
       " (-0.34275391233665053, 'messag'),\n",
       " (-0.33409114774092286, 'free'),\n",
       " (-0.3235588821067054, 'but'),\n",
       " (-0.32198678590179547, 'whi'),\n",
       " (-0.3188833657297255, 'could'),\n",
       " (-0.3077018817854875, 'not'),\n",
       " (-0.30411626066729297, 'redhat'),\n",
       " (-0.30385403751524764, 'show'),\n",
       " (-0.3028353367185478, 'target'),\n",
       " (-0.3007544669958066, 'latest'),\n",
       " (-0.30023178180296634, 'p'),\n",
       " (-0.2998106022435748, 'folder'),\n",
       " (-0.2974162620642277, 'egroup'),\n",
       " (-0.29655348888757094, 'made'),\n",
       " (-0.29444819964336283, 'success'),\n",
       " (-0.287465585290317, 'network'),\n",
       " (-0.283959104354902, 'remov'),\n",
       " (-0.28240503860865396, 'know'),\n",
       " (-0.2770809310823154, 'find'),\n",
       " (-0.2699908222654282, 'said'),\n",
       " (-0.2687283362503128, 'spamassassin'),\n",
       " (-0.2678752703689263, 'href'),\n",
       " (-0.26774885630612655, 'state'),\n",
       " (-0.2661166557074514, 'mailto'),\n",
       " (-0.2618566544588413, 'quit'),\n",
       " (-0.2606691183958501, 'first'),\n",
       " (-0.2597539016134147, 'now'),\n",
       " (-0.2594052015458063, 'see'),\n",
       " (-0.25592095557879596, 'or'),\n",
       " (-0.2534024262534684, 'lot'),\n",
       " (-0.2517779092885412, 'few'),\n",
       " (-0.24929651239805609, 'there'),\n",
       " (-0.2488968094571245, 'one'),\n",
       " (-0.24605475765375778, 'program'),\n",
       " (-0.24595771313655737, 'an'),\n",
       " (-0.2443232000561718, 'in'),\n",
       " (-0.24402009124268903, 'call'),\n",
       " (-0.243303519253407, 'came'),\n",
       " (-0.24281158349072476, 'fork'),\n",
       " (-0.2419671347471092, 'java'),\n",
       " (-0.24138731635279123, 'instruct'),\n",
       " (-0.24051551842220273, 'time'),\n",
       " (-0.2335719098109007, 'relat'),\n",
       " (-0.23081504050220947, 'hour'),\n",
       " (-0.22905466119953663, 'daili'),\n",
       " (-0.22887133818651925, 'trust'),\n",
       " (-0.22626169175815364, 'f'),\n",
       " (-0.2244036071377926, 'polic'),\n",
       " (-0.22393496422102513, 'differ'),\n",
       " (-0.21835633560695578, 'parti'),\n",
       " (-0.21696109372013786, 'wish'),\n",
       " (-0.2153573206585985, 'd'),\n",
       " (-0.21367101888530543, 'citi'),\n",
       " (-0.21152178022522442, 'activ'),\n",
       " (-0.2101785091212557, 'self'),\n",
       " (-0.20995065843460112, 'l'),\n",
       " (-0.2098331463898376, 'search'),\n",
       " (-0.2087763534179587, 'as'),\n",
       " (-0.20789688100792197, 'action'),\n",
       " (-0.20733197863379377, 'it'),\n",
       " (-0.2066789170312666, 'great'),\n",
       " (-0.20550442370160885, 'discov'),\n",
       " (-0.20350820525594693, 'discuss'),\n",
       " (-0.20349243113726662, 'oper'),\n",
       " (-0.1985630584264716, 'about'),\n",
       " (-0.19689157167750151, 'exmh'),\n",
       " (-0.19592256342145187, 'he'),\n",
       " (-0.19477913813137523, 'us'),\n",
       " (-0.1923394528999902, 'perhap'),\n",
       " (-0.190561762964982, 'act')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_words = [(value, word) for value, word in words_and_coefs if value > 0]\n",
    "ham_words = [(value, word) for value, word in words_and_coefs if value < 0] \n",
    "\n",
    "print(\"Anti spam markers\")\n",
    "ham_words.sort()\n",
    "ham_words[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I supposed that 'free' will be an absolute spam marker, but it is not. What if it depends on the context? Say \"free\" + \"url\" separately have weights -0.334 and -0.1867, but together some positive weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam markers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1.4479740530198808, 'set'),\n",
       " (1.3347803360047223, 've'),\n",
       " (0.8786941483810145, 'user'),\n",
       " (0.7503766541133587, 'thing'),\n",
       " (0.7173849687043966, 'googl'),\n",
       " (0.6546377353715828, 'm'),\n",
       " (0.5956335368539786, 'most'),\n",
       " (0.5867489304150983, 'john'),\n",
       " (0.5858107006796366, 'question'),\n",
       " (0.5717247800787512, 'these'),\n",
       " (0.5700211544427483, 'thi'),\n",
       " (0.5508061708571551, 'xent'),\n",
       " (0.4974372460625462, 'book'),\n",
       " (0.4834404347505117, 'move'),\n",
       " (0.4807977922969873, 'high'),\n",
       " (0.4486995924921731, 'rpm'),\n",
       " (0.4465127099301383, 'still'),\n",
       " (0.4439558363659042, 'list'),\n",
       " (0.4291818951902267, 'would'),\n",
       " (0.42848779815639804, 'veri'),\n",
       " (0.42824693185029106, 'yahoo'),\n",
       " (0.42219100894316064, 'them'),\n",
       " (0.4144063686695424, 'un'),\n",
       " (0.41363307672400457, 'report'),\n",
       " (0.38892010712714126, 'we'),\n",
       " (0.37964884487654316, 'send'),\n",
       " (0.37455144920025435, 'copyright'),\n",
       " (0.3735709794191762, 'support'),\n",
       " (0.3730512575243844, 'els'),\n",
       " (0.3724295152851689, 'internet'),\n",
       " (0.3686767905759167, 'site'),\n",
       " (0.35377307098892324, 'they'),\n",
       " (0.3476023804277865, 'sponsor'),\n",
       " (0.34708703115577183, 'market'),\n",
       " (0.3429992371998257, 'commun'),\n",
       " (0.34043079241189206, 'entir'),\n",
       " (0.339800736471953, 'keep'),\n",
       " (0.3392924488434639, 'seem'),\n",
       " (0.33799201964345343, 'razor'),\n",
       " (0.3351162601082263, 'special'),\n",
       " (0.32841753765544635, 'so'),\n",
       " (0.32790308798473106, 'check'),\n",
       " (0.32705392812021966, 'pictur'),\n",
       " (0.32536454607275167, 'those'),\n",
       " (0.32321864084233787, 'last'),\n",
       " (0.3135043701419045, 'without'),\n",
       " (0.2999460966613311, 'top'),\n",
       " (0.2997647542096095, 'happi'),\n",
       " (0.29719580618527897, 'septemb'),\n",
       " (0.29506784000990793, 'guess'),\n",
       " (0.29481813165838483, 'murphi'),\n",
       " (0.2930319832721575, 'enough'),\n",
       " (0.2921382430638963, 'part'),\n",
       " (0.28272662922881614, 'whether'),\n",
       " (0.2766691669328123, 'select'),\n",
       " (0.2723233429037746, 'game'),\n",
       " (0.270960889977394, 'public'),\n",
       " (0.26620115215394746, 'wed'),\n",
       " (0.2634133325294134, 'onc'),\n",
       " (0.2633379301635565, 'script'),\n",
       " (0.25933364398366726, 'prefer'),\n",
       " (0.25752210068161796, 'll'),\n",
       " (0.253717107944065, 'least'),\n",
       " (0.2534233863565562, 'both'),\n",
       " (0.250651663819028, 'addit'),\n",
       " (0.2504338854123138, 'lead'),\n",
       " (0.24995282422220277, 'may'),\n",
       " (0.2481841169031938, 'you'),\n",
       " (0.24689928743001513, 'went'),\n",
       " (0.24422490330985275, 'associ'),\n",
       " (0.2415583105479769, 'chang'),\n",
       " (0.24055796611401817, 'my'),\n",
       " (0.24008944391064913, 'servic'),\n",
       " (0.23640981947505388, 'incom'),\n",
       " (0.23480964184540065, 'women'),\n",
       " (0.2347626801887072, 'wa'),\n",
       " (0.23396572085963468, 'word'),\n",
       " (0.23231643117079506, 're'),\n",
       " (0.23226118408355562, 'off'),\n",
       " (0.23191457963667436, 'speech'),\n",
       " (0.23046196691675855, 'today'),\n",
       " (0.2282711599014932, 'html'),\n",
       " (0.2281875595654746, 'day'),\n",
       " (0.22557149146246327, 'kind'),\n",
       " (0.22314312590933644, 'propos'),\n",
       " (0.22309721556195458, 'particip'),\n",
       " (0.218247209684839, 'spam'),\n",
       " (0.21564123546665367, 'inc'),\n",
       " (0.21526851378781794, 'oct'),\n",
       " (0.2148202622364508, 'fix'),\n",
       " (0.2134391763980875, 'play'),\n",
       " (0.20686943896137955, 'around'),\n",
       " (0.20015970120189974, 'claim'),\n",
       " (0.1978859165825067, 'much'),\n",
       " (0.19726189212659448, 'start'),\n",
       " (0.19605227019345042, 'code'),\n",
       " (0.19458111240756307, 'domain'),\n",
       " (0.1898402030380154, 'coupl'),\n",
       " (0.18872743283881255, 'pudg'),\n",
       " (0.18497789860445388, 'experi')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Spam markers\")\n",
    "spam_words.sort(reverse=True)\n",
    "spam_words[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, what does 've' mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
